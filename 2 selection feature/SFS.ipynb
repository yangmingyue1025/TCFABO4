{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f883ca5-43a3-4da0-a3ee-1b4028a13ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion: R2 Score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import time\n",
    "import os\n",
    "\n",
    "class StableSFS:\n",
    "    def __init__(self, n_features_to_select=7, n_estimators=None, max_depth=None, cv=10, random_state=1, verbose=True):\n",
    "        self.n_features_to_select = n_features_to_select\n",
    "        self.max_depth = max_depth\n",
    "        self.cv = cv\n",
    "        self.random_state = random_state\n",
    "        self.initial_n_estimators = n_estimators\n",
    "        self.n_estimators = n_estimators\n",
    "        self.selected_features_ = None\n",
    "        self.feature_scores_ = {}\n",
    "        self.performance_log_ = []\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def _find_optimal_estimators(self, X, y_input, max_estimators=1000, step=50):\n",
    "        y = y_input\n",
    "        if isinstance(y_input, pd.Series):\n",
    "            y = y_input.values\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"\\n[Seed {self.random_state}] Finding optimal n_estimators...\")\n",
    "\n",
    "        estimator_range = range(50, max_estimators + 1, step)\n",
    "        best_score = -np.inf\n",
    "        best_n = 100\n",
    "        kfold = KFold(n_splits=self.cv, shuffle=True, random_state=self.random_state)\n",
    "\n",
    "        for n in estimator_range:\n",
    "            fold_scores = []\n",
    "            for train_idx, val_idx in kfold.split(X):\n",
    "                X_tr, y_tr = X.iloc[train_idx], y[train_idx]\n",
    "                X_val, y_val = X.iloc[val_idx], y[val_idx]\n",
    "\n",
    "                model = RandomForestRegressor(\n",
    "                    n_estimators=n,\n",
    "                    max_depth=self.max_depth,\n",
    "                    random_state=self.random_state,\n",
    "                    n_jobs=1\n",
    "                )\n",
    "                model.fit(X_tr, y_tr)\n",
    "                pred = model.predict(X_val)\n",
    "                fold_scores.append(r2_score(y_val, pred))\n",
    "\n",
    "            mean_score = np.mean(fold_scores)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"  n_estimators={n:3d} | R²={mean_score:.4f}\")\n",
    "\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_n = n\n",
    "            elif mean_score == best_score and n < best_n:\n",
    "                if self.verbose:\n",
    "                    print(f\"  n_estimators={n:3d} | R² is the same ({mean_score:.4f}), preferring smaller n_estimators (was {best_n})\")\n",
    "                best_n = n\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"[Seed {self.random_state}] Optimal n_estimators: {best_n} (R²={best_score:.4f})\")\n",
    "\n",
    "        return best_n\n",
    "\n",
    "    def _evaluate_feature_stability(self, X, y_input, feature_set):\n",
    "        \"\"\"Evaluate the stability and performance of a given feature subset.\"\"\"\n",
    "        y = y_input\n",
    "        if isinstance(y_input, pd.Series):\n",
    "            y = y_input.values\n",
    "\n",
    "        np.random.seed(self.random_state)\n",
    "        kf = KFold(n_splits=self.cv, shuffle=True, random_state=self.random_state)\n",
    "        fold_scores = []\n",
    "        fold_importances = {feature: [] for feature in feature_set}\n",
    "\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            X_train_fold, y_train_fold = X.iloc[train_idx][feature_set], y[train_idx]\n",
    "            X_val_fold, y_val_fold = X.iloc[val_idx][feature_set], y[val_idx]\n",
    "\n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=self.n_estimators,\n",
    "                max_depth=self.max_depth,\n",
    "                random_state=self.random_state,\n",
    "                n_jobs=1\n",
    "            )\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = model.predict(X_val_fold)\n",
    "            fold_scores.append(r2_score(y_val_fold, y_pred))\n",
    "            \n",
    "            importances = dict(zip(feature_set, model.feature_importances_))\n",
    "            for feature in feature_set:\n",
    "                fold_importances[feature].append(importances[feature])\n",
    "\n",
    "        mean_score = np.mean(fold_scores)\n",
    "        std_score = np.std(fold_scores)\n",
    "        \n",
    "        feature_stability = {}\n",
    "        for feature in feature_set:\n",
    "            mean_importance = np.mean(fold_importances[feature])\n",
    "            std_importance = np.std(fold_importances[feature])\n",
    "            stability_score = mean_importance / (std_importance + 1e-10) # Not used, but calculated\n",
    "            feature_stability[feature] = {\n",
    "                'mean_importance': mean_importance,\n",
    "                'std_importance': std_importance,\n",
    "                'stability_score': stability_score\n",
    "            }\n",
    "        return mean_score, std_score, feature_stability\n",
    "\n",
    "    def fit(self, X, y_input):\n",
    "        \"\"\"Execute stable feature selection - forcing selection of a specified number of features.\"\"\"\n",
    "        y = y_input\n",
    "        if isinstance(y_input, pd.Series):\n",
    "            y = y_input.values\n",
    "\n",
    "        np.random.seed(self.random_state)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"\\n===== [Seed {self.random_state}] Starting Feature Selection =====\")\n",
    "\n",
    "        if self.initial_n_estimators is None:\n",
    "            self.n_estimators = self._find_optimal_estimators(X, y)\n",
    "        elif self.verbose:\n",
    "            print(f\"[Seed {self.random_state}] Using specified n_estimators={self.n_estimators}\")\n",
    "\n",
    "        selected_features = []\n",
    "        remaining_features = sorted(X.columns.tolist())\n",
    "\n",
    "        if \"pm\" in remaining_features:\n",
    "            selected_features.append(\"pm\")\n",
    "            remaining_features.remove(\"pm\")\n",
    "            if self.verbose:\n",
    "                print(f\"[Seed {self.random_state}] Forcing first feature: pm\")\n",
    "        \n",
    "        # SFS main loop\n",
    "        for i in range(len(selected_features), self.n_features_to_select):\n",
    "            if not remaining_features or len(selected_features) >= self.n_features_to_select:\n",
    "                if self.verbose and not remaining_features and len(selected_features) < self.n_features_to_select:\n",
    "                    print(f\"[Seed {self.random_state}] No more features to select. {len(selected_features)} features selected.\")\n",
    "                break\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"\\n[Seed {self.random_state}] Feature Selection Round {i+1} (Selected: {len(selected_features)})\")\n",
    "                print(f\"  Current feature set: {selected_features}\")\n",
    "\n",
    "            best_score_for_round = -np.inf\n",
    "            best_feature_for_round = None\n",
    "            current_evaluations = {}\n",
    "\n",
    "            for feature_to_add in sorted(remaining_features):\n",
    "                candidate_set = selected_features + [feature_to_add]\n",
    "                score, score_std, stability_info = self._evaluate_feature_stability(\n",
    "                    X, y, candidate_set\n",
    "                )\n",
    "                current_evaluations[feature_to_add] = {\n",
    "                    'score': score,\n",
    "                    'std': score_std,\n",
    "                    'stability': stability_info[feature_to_add]['stability_score'] if feature_to_add in stability_info else np.nan\n",
    "                }\n",
    "                if self.verbose:\n",
    "                    print(f\"  Evaluating feature: {feature_to_add:15s} | R²: {score:.4f} ± {score_std:.4f}\")\n",
    "\n",
    "                if score > best_score_for_round:\n",
    "                    best_score_for_round = score\n",
    "                    best_feature_for_round = feature_to_add\n",
    "                elif score == best_score_for_round and best_feature_for_round is not None and feature_to_add < best_feature_for_round:\n",
    "                    best_feature_for_round = feature_to_add\n",
    "\n",
    "            if best_feature_for_round is None:\n",
    "                if self.verbose:\n",
    "                    print(f\"[Seed {self.random_state}] No suitable feature found among remaining or limit reached.\")\n",
    "                break\n",
    "\n",
    "            selected_features.append(best_feature_for_round)\n",
    "            remaining_features.remove(best_feature_for_round)\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"  [Seed {self.random_state}] Round {i+1} selected feature: {best_feature_for_round} (R²: {best_score_for_round:.4f})\")\n",
    "\n",
    "            self.performance_log_.append({\n",
    "                'iteration': i + 1,\n",
    "                'selected': best_feature_for_round,\n",
    "                'current_set': selected_features.copy(),\n",
    "                'score': best_score_for_round,\n",
    "                'evaluations': current_evaluations\n",
    "            })\n",
    "\n",
    "            for feat_eval, eval_data in current_evaluations.items():\n",
    "                if feat_eval not in self.feature_scores_:\n",
    "                    self.feature_scores_[feat_eval] = []\n",
    "                self.feature_scores_[feat_eval].append(eval_data)\n",
    "\n",
    "        self.selected_features_ = selected_features\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"\\n[Seed {self.random_state}] Feature selection complete!\")\n",
    "            print(f\"  Final selected features: {self.selected_features_}\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "        return self\n",
    "\n",
    "def multi_seed_stable_selection(X, y_input, n_seeds=400, target_features=7, start_seed=1, verbose=False):\n",
    "    y = y_input\n",
    "    if isinstance(y_input, pd.Series):\n",
    "        y = y_input.values\n",
    "\n",
    "    seed_results = []\n",
    "    all_selected_features = []\n",
    "    feature_counter = Counter()\n",
    "    collected_n_estimators = []\n",
    "\n",
    "    timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "    # Change the output directory name here\n",
    "    output_dir_base = \"sfspcc400times\"\n",
    "    log_dir = f\"{output_dir_base}_{timestamp}\" \n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_file_path = os.path.join(log_dir, \"sfs_run.log\")\n",
    "\n",
    "    with open(log_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"=== Multi-Seed Stable Feature Selection - Start Time: {time.strftime('%Y-%m-%d %H:%M:%S')} ===\\n\")\n",
    "        f.write(f\"Number of seeds: {n_seeds}, Target features: {target_features}, Start seed: {start_seed}\\n\\n\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Executing stable feature selection with {n_seeds} different random seeds...\")\n",
    "        print(f\"Logs will be saved to: {log_file_path}\")\n",
    "\n",
    "    progress_bar = tqdm(range(n_seeds), desc=\"SFS Progress\")\n",
    "\n",
    "    for i in progress_bar:\n",
    "        current_seed = start_seed + i\n",
    "        progress_bar.set_description(f\"Processing seed {current_seed}\")\n",
    "\n",
    "        selector = StableSFS(\n",
    "            n_features_to_select=target_features,\n",
    "            cv=10,\n",
    "            random_state=current_seed,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        selector.fit(X, y)\n",
    "\n",
    "        current_run_selected_features = selector.selected_features_ if selector.selected_features_ is not None else []\n",
    "        all_selected_features.append(current_run_selected_features)\n",
    "\n",
    "        if selector.n_estimators is not None:\n",
    "            collected_n_estimators.append(selector.n_estimators)\n",
    "\n",
    "        for feature_name in current_run_selected_features:\n",
    "            feature_counter[feature_name] += 1\n",
    "\n",
    "        seed_results.append({\n",
    "            'seed': current_seed,\n",
    "            'features': current_run_selected_features,\n",
    "            'n_estimators': selector.n_estimators\n",
    "        })\n",
    "\n",
    "        with open(log_file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"\\nSeed {current_seed} Results:\\n\")\n",
    "            f.write(f\"  n_estimators: {selector.n_estimators}\\n\")\n",
    "            f.write(f\"  Selected Features: {', '.join(current_run_selected_features)}\\n\")\n",
    "            for j, log_entry in enumerate(selector.performance_log_):\n",
    "                f.write(f\"  Round {j+1}: Selected '{log_entry['selected']}' (CV R²: {log_entry['score']:.4f})\\n\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n===== Multi-Seed Stable Feature Selection Results =====\")\n",
    "        print(f\"Total runs: {n_seeds}\")\n",
    "\n",
    "    sorted_features = sorted(feature_counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nFeature Selection Frequency (descending):\")\n",
    "        for feature_name, count in sorted_features:\n",
    "            percentage = (count / n_seeds) * 100\n",
    "            print(f\"{feature_name}: {count}/{n_seeds} ({percentage:.1f}%)\")\n",
    "\n",
    "    most_stable_features = [f[0] for f in sorted_features[:target_features]]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nRecommended most stable {target_features}-feature set:\")\n",
    "        print(most_stable_features)\n",
    "\n",
    "    with open(log_file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n===== Final Summary =====\\n\")\n",
    "        f.write(\"Feature Selection Frequency (descending):\\n\")\n",
    "        for feature_item_log, count_log in sorted_features:\n",
    "            percentage = (count_log / n_seeds) * 100\n",
    "            f.write(f\"{feature_item_log}: {count_log}/{n_seeds} ({percentage:.1f}%)\\n\")\n",
    "        f.write(f\"\\nRecommended most stable {target_features}-feature set:\\n\")\n",
    "        f.write((\", \".join(most_stable_features) if most_stable_features else \"None\") + \"\\n\")\n",
    "        f.write(f\"\\nRun End Time: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "    if sorted_features:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plot_feature_names_list = [f[0] for f in sorted_features]\n",
    "        plot_counts_list = [f[1] for f in sorted_features]\n",
    "        bars = plt.bar(plot_feature_names_list, plot_counts_list)\n",
    "        plt.axhline(y=n_seeds/2, color='r', linestyle='--', label='50% Selection Rate')\n",
    "        for i, feature_name_in_plot in enumerate(plot_feature_names_list):\n",
    "            if feature_name_in_plot in most_stable_features:\n",
    "                bars[i].set_color('green')\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Selection Frequency')\n",
    "        plt.title('Feature Selection Frequency Distribution')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.legend(['50% Selection Rate', 'Most Stable Features'])\n",
    "        plt.savefig(os.path.join(log_dir, 'feature_selection_frequency.png'))\n",
    "        plt.close()\n",
    "        if verbose: print(f\"Plot saved to: {os.path.join(log_dir, 'feature_selection_frequency.png')}\")\n",
    "\n",
    "    if sorted_features:\n",
    "        result_df = pd.DataFrame({\n",
    "            'feature': [f[0] for f in sorted_features],\n",
    "            'selection_frequency': [f[1] for f in sorted_features],\n",
    "            'percentage': [f[1]/n_seeds*100 for f in sorted_features]\n",
    "        })\n",
    "        result_df.to_csv(os.path.join(log_dir, 'feature_selection_results.csv'), index=False)\n",
    "        if verbose: print(f\"Results CSV saved to: {os.path.join(log_dir, 'feature_selection_results.csv')}\")\n",
    "\n",
    "    if seed_results:\n",
    "        seed_df = pd.DataFrame(seed_results)\n",
    "        seed_df['features'] = seed_df['features'].apply(lambda x: ', '.join(x) if isinstance(x, list) else '')\n",
    "        seed_df.to_csv(os.path.join(log_dir, 'seed_details.csv'), index=False)\n",
    "        if verbose: print(f\"Seed details CSV saved to: {os.path.join(log_dir, 'seed_details.csv')}\")\n",
    "\n",
    "    return most_stable_features, sorted_features, seed_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"===== Multi-Seed SFS Feature Selection based on Random Forest =====\")\n",
    "\n",
    "    try:\n",
    "        data_path = \"/Users/yangmingyue/Desktop/78/降维后PCC/ABO478PCC.csv\" # Data file path\n",
    "        data = pd.read_csv(data_path)\n",
    "        print(f\"Data dimensions: {data.shape[0]} rows x {data.shape[1]} columns\")\n",
    "\n",
    "        target_column = \"TCF\" # Target variable column name\n",
    "        if target_column not in data.columns:\n",
    "            raise ValueError(f\"Column not found: {target_column}\")\n",
    "\n",
    "        X = data.drop(columns=[target_column])\n",
    "        y_series = data[target_column]\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Data file '{data_path}' not found.\")\n",
    "        exit(1)\n",
    "    except ValueError as ve:\n",
    "        print(f\"Data processing error: {ve}\")\n",
    "        exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while loading data: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    if X.empty or y_series.empty:\n",
    "        print(\"Error: Feature set X or target set y is empty.\")\n",
    "        exit(1)\n",
    "    if X.shape[0] < 5:\n",
    "        print(f\"Error: Not enough data samples ({X.shape[0]} rows). At least 5 are needed for effective cross-validation.\")\n",
    "        exit(1)\n",
    "\n",
    "    print(f\"Features: {X.shape[1]} columns, Samples: {X.shape[0]} rows\")\n",
    "\n",
    "    # Change the number of seeds here\n",
    "    n_seeds_input = 400 \n",
    "    target_features_input = 7\n",
    "    verbose_input = input(\"Show detailed logs? (y/n, default: n): \").strip().lower() == 'y'\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    most_stable_features_res, feature_freq_res, seed_details_res = multi_seed_stable_selection(\n",
    "        X, y_series,\n",
    "        n_seeds=n_seeds_input,\n",
    "        target_features=target_features_input,\n",
    "        start_seed=1,\n",
    "        verbose=verbose_input\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"\\nTotal execution time: {(end_time - start_time) / 60:.2f} minutes\")\n",
    "    print(\"\\nFeature Selection Frequency (descending, showing top 17):\")\n",
    "    if feature_freq_res:\n",
    "        for feature_item_print, count_print in feature_freq_res[:17]:\n",
    "            percentage = (count_print / n_seeds_input) * 100\n",
    "            print(f\"{feature_item_print}: {count_print}/{n_seeds_input} ({percentage:.1f}%)\")\n",
    "    else:\n",
    "        print(\"No features were selected or counted.\")\n",
    "\n",
    "    print(f\"\\nRecommended most stable {target_features_input}-feature set:\")\n",
    "    if most_stable_features_res:\n",
    "        print(\", \".join(most_stable_features_res))\n",
    "    else:\n",
    "        print(\"Could not determine a stable feature set.\")\n",
    "\n",
    "    print(\"\\nProcessing complete! All results have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
